{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from typing import List, Dict, Any\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set up OpenRouter with OpenAI client\n",
    "OPENROUTER_API_KEY = \"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\"\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "embeddings_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Connect to Qdrant (local or cloud)\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://8b6857da-0682-417b-a31b-2a83bef2cab3.us-east-1-0.aws.cloud.qdrant.io\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.dWjs7ZnPcyo0lbk1tvelYBim14HKNwDm1qfWTKaoVoQ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18 entries from JSON file\n"
     ]
    }
   ],
   "source": [
    "def read_json_file(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Read JSON file and return its contents.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Read the data\n",
    "file_path = \"../data/processed/Class_Schedule.json\"\n",
    "admission_data = read_json_file(file_path)\n",
    "print(f\"Loaded {len(admission_data)} entries from JSON file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Generate embedding for a text using OpenAI's text-embeddings-small-3 model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    response = embeddings_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    embedding_time = time.time() - start_time\n",
    "    print(f\"Embedding time: {embedding_time} seconds\")\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def create_payload(entry: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Create a payload with text, keywords, and metadata for Qdrant.\"\"\"\n",
    "    text = entry.get(\"text\", \"\")\n",
    "    keywords = entry.get(\"keywords\", [])\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"keywords\": keywords,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection class_schedule\n"
     ]
    }
   ],
   "source": [
    "def create_collection(collection_name: str, vector_size: int = 1536):\n",
    "    \"\"\"Create a collection in Qdrant if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        qdrant_client.get_collection(collection_name)\n",
    "        print(f\"Collection {collection_name} already exists\")\n",
    "    except Exception:\n",
    "        qdrant_client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=models.VectorParams(\n",
    "                size=vector_size,\n",
    "                distance=models.Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "        print(f\"Created collection {collection_name}\")\n",
    "\n",
    "# Create collection for admission data\n",
    "create_collection(\"class_schedule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding time: 0.6798524856567383 seconds\n",
      "Embedding time: 1.4361741542816162 seconds\n",
      "Embedding time: 0.5141494274139404 seconds\n",
      "Embedding time: 0.609935998916626 seconds\n",
      "Embedding time: 0.6175282001495361 seconds\n",
      "Embedding time: 0.41523170471191406 seconds\n",
      "Embedding time: 0.8901839256286621 seconds\n",
      "Embedding time: 1.161759376525879 seconds\n",
      "Embedding time: 0.49821972846984863 seconds\n",
      "Embedding time: 0.4081695079803467 seconds\n",
      "Uploaded batch 1/2\n",
      "Embedding time: 0.5092024803161621 seconds\n",
      "Embedding time: 0.7208588123321533 seconds\n",
      "Embedding time: 0.44847536087036133 seconds\n",
      "Embedding time: 1.3901169300079346 seconds\n",
      "Embedding time: 0.513908863067627 seconds\n",
      "Embedding time: 0.6163101196289062 seconds\n",
      "Embedding time: 1.0241820812225342 seconds\n",
      "Embedding time: 0.5073039531707764 seconds\n",
      "Uploaded batch 2/2\n",
      "All data processed and uploaded to Qdrant\n"
     ]
    }
   ],
   "source": [
    "def process_and_upload_data(data: List[Dict[str, Any]], collection_name: str):\n",
    "    \"\"\"Process each entry, generate embedding, and upload to Qdrant.\"\"\"\n",
    "    batch_size = 10  # Process in batches to avoid API rate limits\n",
    "    \n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        \n",
    "        points = []\n",
    "        for j, entry in enumerate(batch):\n",
    "            # Create payload with text and keywords\n",
    "            payload = create_payload(entry)\n",
    "            \n",
    "            # Generate embedding for text content\n",
    "            embedding = generate_embedding(entry[\"text\"])\n",
    "            \n",
    "            # Add to points\n",
    "            points.append(models.PointStruct(\n",
    "                id=i+j,\n",
    "                vector=embedding,\n",
    "                payload=payload\n",
    "            ))\n",
    "        \n",
    "        # Upload batch to Qdrant\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points\n",
    "        )\n",
    "        \n",
    "        print(f\"Uploaded batch {i//batch_size + 1}/{(len(data) + batch_size - 1)//batch_size}\")\n",
    "\n",
    "# Process and upload data\n",
    "process_and_upload_data(admission_data, \"class_schedule\")\n",
    "print(\"All data processed and uploaded to Qdrant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant_simple(query: str, collection_name: str, limit) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Perform simple search in Qdrant for a single query.\"\"\"\n",
    "    # Generate embedding for the query\n",
    "    embedding = generate_embedding(query)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Perform search\n",
    "    search_results = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=embedding,\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )\n",
    "    print(search_results)\n",
    "    print(len(search_results))\n",
    "    search_time = time.time() - start_time\n",
    "    print(f\"Search time: {search_time} seconds\")\n",
    "    # Format results\n",
    "\n",
    "    # Format results\n",
    "    results = []\n",
    "    for scored_point in search_results:\n",
    "        results.append({\n",
    "            \"id\": scored_point.id,\n",
    "            \"score\": scored_point.score,\n",
    "            \"payload\": scored_point.payload\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query: str, context: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"Generate a response using OpenAI based on retrieved context.\"\"\"\n",
    "    # Prepare context text from search results\n",
    "    start_time = time.time()\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Document {i+1}:\\nText: {item['payload']['text']}\\nKeywords: {', '.join(item['payload']['keywords'])}\"\n",
    "        for i, item in enumerate(context)\n",
    "    ])\n",
    "    context_time = time.time() - start_time\n",
    "    print(f\"Context time: {context_time} seconds\")\n",
    "    system_prompt = \"\"\"\n",
    "    You are an authoritative academic assistant for Notre Dame University (NDU) providing precise class schedule information.\n",
    "    \n",
    "    IMPORTANT GUIDELINES:\n",
    "    1. For schedule queries, provide exact days, times, and course details from the retrieved documents.\n",
    "    2. Format schedule information clearly with course code, name, days, and times in a structured format.\n",
    "    3. When multiple schedules are retrieved, prioritize the specific course mentioned in the query.\n",
    "    4. If schedule information is incomplete or not found in the context, state this explicitly and suggest contacting the registrar.\n",
    "    5. Use bold formatting for key details like course codes, days, and times.\n",
    "\n",
    "    Provide only factual information based on the retrieved documents. Never invent or assume schedule details.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"Question: {query}\\n\\nContext:\\n{context_text}\"\n",
    "    start_time_1 = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-4o\",  # Using a powerful model for response generation\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    response_time = time.time() - start_time_1\n",
    "    print(f\"Response time: {response_time} seconds\")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline_simple(query: str):\n",
    "    \"\"\"Complete RAG pipeline from user query to response.\"\"\"\n",
    "    print(f\"Original query: {query}\")\n",
    "    \n",
    "    # Search Qdrant with a single query\n",
    "    search_results = search_qdrant_simple(query, \"class_schedule\", limit=6)\n",
    "    \n",
    "    # Generate response\n",
    "    response = generate_response(query, search_results)\n",
    "    \n",
    "    return {\n",
    "        \"original_query\": query,\n",
    "        \"search_results\": search_results,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: What classes do I have on tuesday?\n",
      "Embedding time: 1.2459297180175781 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zohai\\AppData\\Local\\Temp\\ipykernel_25784\\1499742798.py:8: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ScoredPoint(id=12, version=2, score=0.43175754, payload={'text': \"Course Schedule: MTH 110 - Pre-Calculus Mathematics\\nThe course MTH 110, titled 'Pre-Calculus Mathematics', for the Bachelor of Science in Computer Science program, is scheduled as follows: Sunday from 14:00 to 15:30, Monday from 14:00 to 15:30.\", 'keywords': ['MTH 110', 'Pre-Calculus Mathematics', 'schedule', 'timetable', 'class times', 'BSCS', 'Sunday', 'Monday', '14:00-15:30']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=6, version=1, score=0.42570692, payload={'text': \"Course Schedule: CSC 312 - Computer Architecture\\nThe course CSC 312, titled 'Computer Architecture', for the Bachelor of Science in Computer Science program, is scheduled as follows: Sunday from 11:00 to 12:30, Monday from 11:00 to 12:30.\", 'keywords': ['CSC 312', 'Computer Architecture', 'schedule', 'timetable', 'class times', 'BSCS', 'Sunday', 'Monday', '11:00-12:30']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=7, version=1, score=0.4171738, payload={'text': \"Course Schedule: CSC 317 - Information Assurance and Security\\nThe course CSC 317, titled 'Information Assurance and Security', for the Bachelor of Science in Computer Science program, is scheduled as follows: Tuesday from 11:00 to 12:30, Wednesday from 11:00 to 12:30.\", 'keywords': ['CSC 317', 'Information Assurance and Security', 'schedule', 'timetable', 'class times', 'BSCS', 'Tuesday', 'Wednesday', '11:00-12:30']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=9, version=1, score=0.4138025, payload={'text': \"Course Schedule: CSC 316 - Fundamentals of Computer Security\\nThe course CSC 316, titled 'Fundamentals of Computer Security', for the Bachelor of Science in Computer Science program, is scheduled as follows: Sunday from 12:30 to 14:00, Monday from 12:30 to 14:00.\", 'keywords': ['CSC 316', 'Fundamentals of Computer Security', 'schedule', 'timetable', 'class times', 'BSCS', 'Sunday', 'Monday', '12:30-14:00']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=17, version=2, score=0.40876764, payload={'text': \"Course Schedule: ENG 101 - English Composition\\nThe course ENG 101, titled 'English Composition', for the Bachelor of Science in Computer Science program, is scheduled as follows: Thursday from 15:30 to 17:00.\", 'keywords': ['ENG 101', 'English Composition', 'schedule', 'timetable', 'class times', 'BSCS', 'Thursday', '15:30-17:00']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=13, version=2, score=0.4081006, payload={'text': \"Course Schedule: CSC 450 - Human-Computer Interaction\\nThe course CSC 450, titled 'Human-Computer Interaction', for the Bachelor of Science in Computer Science program, is scheduled as follows: Tuesday from 14:00 to 15:30, Wednesday from 14:00 to 15:30.\", 'keywords': ['CSC 450', 'Human-Computer Interaction', 'schedule', 'timetable', 'class times', 'BSCS', 'Tuesday', 'Wednesday', '14:00-15:30']}, vector=None, shard_key=None, order_value=None)]\n",
      "6\n",
      "Search time: 1.9942481517791748 seconds\n",
      "Context time: 0.0 seconds\n",
      "Response time: 3.7155399322509766 seconds\n",
      "Total time taken: 6.962328672409058 seconds\n",
      "\n",
      "Final Response:\n",
      "Based on the retrieved documents, you have the following classes on Tuesday:\n",
      "\n",
      "1. **CSC 317 - Information Assurance and Security**: **Tuesday, 11:00 to 12:30**\n",
      "2. **CSC 450 - Human-Computer Interaction**: **Tuesday, 14:00 to 15:30**\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline with a sample query\n",
    "start_time = time.time()\n",
    "result = rag_pipeline_simple(\"What classes do I have on tuesday?\")\n",
    "end_time = time.time()\n",
    "print(f\"Total time taken: {end_time - start_time} seconds\")\n",
    "# Display the response\n",
    "print(\"\\nFinal Response:\")\n",
    "print(result[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-kuwait-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
