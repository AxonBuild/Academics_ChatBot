{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 39,
=======
   "cell_type": "markdown",
>>>>>>> Json_POC
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from typing import List, Dict, Any\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import PyPDF2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up OpenRouter with OpenAI client\n",
    "OPENROUTER_API_KEY = \"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\"\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "embeddings_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Connect to Qdrant (local or cloud)\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://8b6857da-0682-417b-a31b-2a83bef2cab3.us-east-1-0.aws.cloud.qdrant.io\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.dWjs7ZnPcyo0lbk1tvelYBim14HKNwDm1qfWTKaoVoQ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18 entries from JSON file\n"
     ]
    }
   ],
=======
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Extract text from PDF and split into chunks with metadata.\"\"\"\n",
    "    print(f\"Processing PDF file: {pdf_path}\")\n",
    "    \n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        num_pages = len(reader.pages)\n",
    "        print(f\"PDF has {num_pages} pages\")\n",
    "        \n",
    "        # Extract text from each page\n",
    "        all_text = \"\"\n",
    "        for i in range(num_pages):\n",
    "            page = reader.pages[i]\n",
    "            text = page.extract_text()\n",
    "            all_text += text + \"\\n\\n\"\n",
    "    \n",
    "    # Split the text into chunks of reasonable size (~1000 characters)\n",
    "    chunks = []\n",
    "    \n",
    "    # Split by sections/paragraphs (adjust as needed based on PDF structure)\n",
    "    raw_chunks = re.split(r'\\n\\s*\\n', all_text)\n",
    "    \n",
    "    current_chunk = \"\"\n",
    "    for chunk in raw_chunks:\n",
    "        if not chunk.strip():\n",
    "            continue\n",
    "            \n",
    "        if len(current_chunk) + len(chunk) < 1000:\n",
    "            current_chunk += chunk + \"\\n\\n\"\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                # Extract potential keywords (simple heuristic: capitalized words)\n",
    "                keywords = re.findall(r'\\b[A-Z][A-Za-z]{2,}\\b', current_chunk)\n",
    "                keywords = list(set([k for k in keywords if k.lower() not in stopwords.words('english')]))[:10]\n",
    "                \n",
    "                chunks.append({\n",
    "                    \"text\": current_chunk.strip(),\n",
    "                    \"keywords\": keywords\n",
    "                })\n",
    "            current_chunk = chunk + \"\\n\\n\"\n",
    "    \n",
    "    # Add the last chunk if not empty\n",
    "    if current_chunk.strip():\n",
    "        keywords = re.findall(r'\\b[A-Z][A-Za-z]{2,}\\b', current_chunk)\n",
    "        keywords = list(set([k for k in keywords if k.lower() not in stopwords.words('english')]))[:10]\n",
    "        \n",
    "        chunks.append({\n",
    "            \"text\": current_chunk.strip(),\n",
    "            \"keywords\": keywords\n",
    "        })\n",
    "    \n",
    "    print(f\"Split PDF into {len(chunks)} chunks\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Handling and Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
>>>>>>> Json_POC
   "source": [
    "def read_json_file(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Read JSON file and return its contents.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
<<<<<<< HEAD
    "# Read the data\n",
    "file_path = \"../data/processed/professor_data.json\"\n",
    "admission_data = read_json_file(file_path)\n",
    "print(f\"Loaded {len(admission_data)} entries from JSON file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
=======
>>>>>>> Json_POC
    "def generate_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Generate embedding for a text using OpenAI's text-embeddings-small-3 model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    response = embeddings_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    embedding_time = time.time() - start_time\n",
    "    print(f\"Embedding time: {embedding_time} seconds\")\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def create_payload(entry: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Create a payload with text, keywords, and metadata for Qdrant.\"\"\"\n",
    "    text = entry.get(\"text\", \"\")\n",
    "    keywords = entry.get(\"keywords\", [])\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"keywords\": keywords,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qdrant Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection professor_data_json\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> Json_POC
   "source": [
    "def create_collection(collection_name: str, vector_size: int = 1536):\n",
    "    \"\"\"Create a collection in Qdrant if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        qdrant_client.get_collection(collection_name)\n",
    "        print(f\"Collection {collection_name} already exists\")\n",
    "    except Exception:\n",
    "        qdrant_client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=models.VectorParams(\n",
    "                size=vector_size,\n",
    "                distance=models.Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "        print(f\"Created collection {collection_name}\")\n",
    "\n",
<<<<<<< HEAD
    "# Create collection for admission data\n",
    "create_collection(\"professor_data_json\")"
=======
    "def process_and_upload_data(data: List[Dict[str, Any]], collection_name: str):\n",
    "    \"\"\"Process each entry, generate embedding, and upload to Qdrant.\"\"\"\n",
    "    batch_size = 10  # Process in batches to avoid API rate limits\n",
    "\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "\n",
    "        points = []\n",
    "        for j, entry in enumerate(batch):\n",
    "            # Create payload with text and keywords\n",
    "            payload = create_payload(entry)\n",
    "\n",
    "            # Generate embedding for text content\n",
    "            embedding = generate_embedding(entry[\"text\"])\n",
    "\n",
    "            # Add to points\n",
    "            points.append(models.PointStruct(\n",
    "                id=i+j,\n",
    "                vector=embedding,\n",
    "                payload=payload\n",
    "            ))\n",
    "\n",
    "        # Upload batch to Qdrant\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points\n",
    "        )\n",
    "\n",
    "        print(f\"Uploaded batch {i//batch_size + 1}/{(len(data) + batch_size - 1)//batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing and Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_and_upload(pdf_path: str, collection_name: str = \"admission_course_guide\"):\n",
    "    \"\"\"Process a PDF file and upload its embeddings to Qdrant.\"\"\"\n",
    "    # Extract text from PDF\n",
    "    pdf_data = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Create collection\n",
    "    create_collection(collection_name)\n",
    "    \n",
    "    # Process and upload data\n",
    "    process_and_upload_data(pdf_data, collection_name)\n",
    "    \n",
    "    print(f\"PDF {pdf_path} processed and uploaded to Qdrant collection {collection_name}\")\n",
    "    return pdf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append PDF to Collection"
>>>>>>> Json_POC
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding time: 1.900301456451416 seconds\n",
      "Embedding time: 33.79106831550598 seconds\n",
      "Embedding time: 1.0530693531036377 seconds\n",
      "Embedding time: 1.2480883598327637 seconds\n",
      "Embedding time: 0.5705008506774902 seconds\n",
      "Embedding time: 1.1462488174438477 seconds\n",
      "Embedding time: 0.7272534370422363 seconds\n",
      "Embedding time: 0.3762781620025635 seconds\n",
      "Embedding time: 0.39932966232299805 seconds\n",
      "Embedding time: 0.40734314918518066 seconds\n",
      "Uploaded batch 1/2\n",
      "Embedding time: 0.4544181823730469 seconds\n",
      "Embedding time: 0.7024495601654053 seconds\n",
      "Embedding time: 0.5683548450469971 seconds\n",
      "Embedding time: 0.4738025665283203 seconds\n",
      "Embedding time: 0.6143655776977539 seconds\n",
      "Embedding time: 0.36043286323547363 seconds\n",
      "Embedding time: 1.1030092239379883 seconds\n",
      "Embedding time: 0.3495752811431885 seconds\n",
      "Uploaded batch 2/2\n",
      "All data processed and uploaded to Qdrant\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> Json_POC
   "source": [
    "def append_pdf_to_collection(pdf_path: str, collection_name: str = \"admission_course_guide\"):\n",
    "    \"\"\"Process a PDF file and append its embeddings to an existing Qdrant collection.\"\"\"\n",
    "    # Extract text from PDF\n",
    "    pdf_data = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Verify collection exists\n",
    "    try:\n",
    "        collection_info = qdrant_client.get_collection(collection_name)\n",
    "        print(f\"Found existing collection {collection_name}\")\n",
    "    except Exception:\n",
    "        print(f\"Collection {collection_name} does not exist, creating it...\")\n",
    "        create_collection(collection_name)\n",
    "    \n",
    "    # Get the count of existing points to avoid ID conflicts\n",
    "    collection_info = qdrant_client.get_collection(collection_name)\n",
    "    existing_points = 12\n",
    "    print(f\"Collection has {existing_points} existing points\")\n",
    "    \n",
    "    # Process in batches to avoid API rate limits\n",
    "    batch_size = 10\n",
    "    for i in range(0, len(pdf_data), batch_size):\n",
    "        batch = pdf_data[i:i+batch_size]\n",
    "        \n",
    "        points = []\n",
    "        for j, entry in enumerate(batch):\n",
    "            # Create payload with text and keywords\n",
    "            payload = create_payload(entry)\n",
    "            \n",
    "            # Generate embedding for text content\n",
    "            embedding = generate_embedding(entry[\"text\"])\n",
    "            \n",
    "            # Add to points with offset IDs to avoid conflicts\n",
    "            points.append(models.PointStruct(\n",
    "                id=existing_points + i + j,\n",
    "                vector=embedding,\n",
    "                payload=payload\n",
    "            ))\n",
    "        \n",
    "        # Upload batch to Qdrant\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points\n",
    "        )\n",
    "        \n",
<<<<<<< HEAD
    "        print(f\"Uploaded batch {i//batch_size + 1}/{(len(data) + batch_size - 1)//batch_size}\")\n",
    "\n",
    "# Process and upload data\n",
    "process_and_upload_data(admission_data, \"professor_data_json\")\n",
    "print(\"All data processed and uploaded to Qdrant\")"
=======
    "        print(f\"Uploaded batch {i//batch_size + 1}/{(len(pdf_data) + batch_size - 1)//batch_size}\")\n",
    "    \n",
    "    print(f\"PDF {pdf_path} processed and appended to Qdrant collection {collection_name}\")\n",
    "    return pdf_data"
>>>>>>> Json_POC
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant_simple(query: str, collection_name: str, limit: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Perform simple search in Qdrant for a single query.\"\"\"\n",
    "    # Generate embedding for the query\n",
    "    embedding = generate_embedding(query)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Perform search\n",
    "    search_results = qdrant_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=embedding,\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "        score_threshold=0.4\n",
    "    )\n",
    "    print(search_results)\n",
    "    search_time = time.time() - start_time\n",
    "    print(f\"Search time: {search_time} seconds\")\n",
    "    \n",
    "    start_time_1 = time.time()\n",
    "    results = []\n",
    "    for scored_point in search_results.points:\n",
    "        results.append({\n",
    "            \"id\": scored_point.id,\n",
    "            \"score\": scored_point.score,\n",
    "            \"payload\": scored_point.payload\n",
    "        })\n",
    "    format_time = time.time() - start_time_1\n",
    "    print(f\"Format time: {format_time} seconds\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query: str, context: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"Generate a response using OpenAI based on retrieved context.\"\"\"\n",
    "    # Prepare context text from search results\n",
    "    start_time = time.time()\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Document {i+1}:\\nText: {item['payload']['text']}\\nKeywords: {', '.join(item['payload']['keywords'])}\"\n",
    "        for i, item in enumerate(context)\n",
    "    ])\n",
    "    context_time = time.time() - start_time\n",
    "    print(f\"Context time: {context_time} seconds\")\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    You are an authoritative academic assistant for Notre Dame University (NDU) providing precise information based on the retrieved documents.\n",
    "\n",
    "    IMPORTANT GUIDELINES:\n",
    "    1. Provide ONLY ONE definitive answer based on the highest relevance matches in the context.\n",
    "    2. If multiple potential answers exist, choose the one with the strongest evidence in the retrieved documents.\n",
    "\n",
    "    Your goal is to provide the single most accurate answer as if you were an official university representative.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"Question: {query}\\n\\nContext:\\n{context_text}\"\n",
    "    start_time_1 = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-4o\",  # Using a powerful model for response generation\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    response_time = time.time() - start_time_1\n",
    "    print(f\"Response time: {response_time} seconds\")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline_simple(query: str, collection_name: str = \"admission_course_guide\"):\n",
    "    \"\"\"Complete RAG pipeline from user query to response.\"\"\"\n",
    "    print(f\"Original query: {query}\")\n",
    "\n",
    "    # Search Qdrant with a single query\n",
    "    search_results = search_qdrant_simple(query, collection_name, limit=3)\n",
    "\n",
    "    # Generate response\n",
    "    response = generate_response(query, search_results)\n",
    "\n",
    "    return {\n",
    "        \"original_query\": query,\n",
    "        \"search_results\": search_results,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage - Process PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Process a PDF file and upload to Qdrant\n",
    "pdf_path = \"../data/raw/admission guide.pdf\"  # Update with your PDF path\n",
    "\n",
    "# Check if the PDF file exists\n",
    "if os.path.exists(pdf_path):\n",
    "    # Process the PDF and upload to Qdrant\n",
    "    processed_data = process_pdf_and_upload(pdf_path)\n",
    "    print(\"PDF processed and uploaded successfully\")\n",
    "else:\n",
    "    print(f\"Error: PDF file not found at {pdf_path}\")\n",
    "    print(\"Please specify the correct path to your PDF file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage - Append Another PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to append another document to the same collection:\n",
    "second_pdf_path = \"../data/raw/Nazir Hawi.pdf\"\n",
    "if os.path.exists(second_pdf_path):\n",
    "    append_pdf_to_collection(second_pdf_path)\n",
    "    print(\"Second PDF appended successfully\")\n",
    "else:\n",
    "    print(f\"Warning: Second PDF file not found at {second_pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage - Test Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: How many credits does a computer science major have?\n",
      "Embedding time: 0.8634097576141357 seconds\n",
      "points=[ScoredPoint(id=14, version=5, score=0.64623094, payload={'text': 'Bachelor of Science in Computer Science - ABET Accredited Program\\nCSC 450 Human-Computer Interaction (3 credits)\\nDescription: Design and evaluation of user interfaces, usability principles, and user experience design.\\nPrerequisite: CSC 305 System Analysis and Design.\\nCSC 463 Advanced Software Development (3 credits)\\nDescription: Techniques and practices for building large-scale, maintainable software systems.\\nPrerequisite: CSC 305 System Analysis and Design.\\nCSC 480 Internship (3 credits)\\nDescription: Practical experience in the IT field to apply academic knowledge in a professional environment.\\nPrerequisite: Completion of at least 90 credits.\\nCSC 490 Senior Study (3 credits)\\nDescription: Capstone project involving research, development, and presentation in a specialized computing\\narea.\\nPrerequisite: Final year standing and departmental approval.\\nLiberal Arts Curriculum\\nENG 101 English Composition (3 credits)\\nDescription: Development of writing skills, including grammar, composition, and research paper techniques.\\nPrerequisite: None.\\nMTH 110 Pre-Calculus Mathematics (3 credits)\\nDescription: Fundamental concepts in algebra and trigonometry as preparation for calculus.', 'keywords': ['Advanced', 'Prerequisite', 'Human', 'Computer', 'Description', 'Arts', 'Techniques', 'Development', 'ENG', 'Program']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=12, version=3, score=0.6060892, payload={'text': 'Bachelor of Science in Computer Science - ABET Accredited Program\\nCSC 226 Introduction to Database (3 credits)\\nDescription: Fundamentals of database systems, data modeling, relational databases, and SQL.\\nPrerequisite: Introduction to Programming.\\nCSC 305 System Analysis and Design (3 credits)\\nDescription: Study of system development life cycle (SDLC), requirements gathering, analysis, and design\\ntechniques.\\nPrerequisite: CSC 226 Introduction to Database.\\nCSC 312 Computer Architecture (3 credits)\\nDescription: Organization and structure of computer systems, instruction sets, and assembly language\\nprogramming.\\nPrerequisite: Introduction to Computer Science.\\nCSC 316 Fundamentals of Computer Security (3 credits)\\nDescription: Basic concepts of securing systems, cryptography, network security, and threat mitigation.\\nPrerequisite: CSC 312 Computer Architecture.\\nCSC 317 Information Assurance and Security (3 credits)\\nDescription: Strategies to ensure data integrity, availability, and confidentiality within IT environments.\\nPrerequisite: CSC 316 Fundamentals of Computer Security.\\nCSC 345 Fundamentals of Computer Network Management (3 credits)\\nDescription: Principles of managing computer networks, including protocols, architectures, and network', 'keywords': ['Prerequisite', 'Information', 'Computer', 'Programming', 'Description', 'Principles', 'Program', 'Database', 'System', 'Management']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=13, version=4, score=0.6012268, payload={'text': 'Bachelor of Science in Computer Science - ABET Accredited Program\\ntroubleshooting.\\nPrerequisite: CSC 312 Computer Architecture.\\nCSC 385 Internet Computing (3 credits)\\nDescription: Technologies behind web applications, internet protocols, and web development principles.\\nPrerequisite: CSC 226 Introduction to Database.\\nCSC 405 Systems Integration (3 credits)\\nDescription: Combining different computing systems and software applications to function as a coordinated\\nwhole.\\nPrerequisite: CSC 305 System Analysis and Design.\\nCSC 414 Applied Operating Systems (3 credits)\\nDescription: In-depth study of operating system concepts, including process management, memory\\nmanagement, and file systems.\\nPrerequisite: CSC 312 Computer Architecture.\\nCSC 425 Data Communications and Computer Networks (3 credits)\\nDescription: Covers transmission methods, network design, TCP/IP protocols, and wireless communication.\\nPrerequisite: CSC 345 Fundamentals of Computer Network Management.\\nCSC 446 Applied Database Systems (3 credits)\\nDescription: Advanced database concepts, database design, and database-driven application development.\\nPrerequisite: CSC 226 Introduction to Database.', 'keywords': ['Advanced', 'TCP', 'Prerequisite', 'Computer', 'Description', 'Data', 'Applied', 'Internet', 'Program', 'Systems']}, vector=None, shard_key=None, order_value=None)]\n",
      "Search time: 3.9852256774902344 seconds\n",
      "Format time: 0.0 seconds\n",
      "Context time: 0.0 seconds\n",
      "Response time: 3.1622016429901123 seconds\n",
      "Total time taken: 8.01184606552124 seconds\n",
      "\n",
      "Final Response:\n",
      "The retrieved documents do not specify the total number of credits required for a Bachelor of Science in Computer Science at Notre Dame University. They provide information on individual courses and their credit values, but not the overall credit requirement for the major.\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline with a sample query\n",
    "start_time = time.time()\n",
    "result = rag_pipeline_simple(\"How many credits does a computer science major have?\")\n",
    "end_time = time.time()\n",
    "print(f\"Total time taken: {end_time - start_time} seconds\")\n",
    "\n",
    "# Display the response\n",
    "print(\"\\nFinal Response:\")\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_variations(query: str) -> List[str]:\n",
    "    \"\"\"Generate variations of the query using OpenAI.\"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    Create one alternative versions of the user's query. \n",
    "    Each version should:\n",
    "    1. Maintain the original meaning\n",
    "    2. Use different wording or phrasing\n",
    "    3. Be a complete, well-formed question\n",
    "    \n",
    "    Return ONLY two variations, one per line, with no additional text.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-4.1-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    \n",
    "    variations_text = response.choices[0].message.content\n",
    "    variations = [line.strip() for line in variations_text.split('\\n') if line.strip()]\n",
    "    \n",
    "    # Ensure we have exactly 2 variations\n",
    "    if len(variations) > 1:\n",
    "        variations = variations[:1]\n",
    "    while len(variations) < 1:\n",
    "        variations.append(query)  # Use original query as fallback\n",
    "        \n",
    "    return variations"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant(queries: List[str], collection_name: str, limit: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Perform batch search in Qdrant for multiple queries.\"\"\"\n",
    "    # Generate embeddings for all queries\n",
    "    query_embeddings = []\n",
    "    for query in queries:\n",
    "        embedding = generate_embedding(query)\n",
    "        query_embeddings.append(embedding)\n",
    "    \n",
    "    # Perform batch search\n",
    "    search_results = qdrant_client.query_batch_points(\n",
    "        collection_name=collection_name,\n",
    "        requests=[\n",
    "            models.QueryRequest(\n",
    "                query=embedding,\n",
    "                limit=limit,\n",
    "                with_payload=True\n",
    "            )\n",
    "            for embedding in query_embeddings\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(search_results)\n",
    "\n",
    "    # Extract unique results\n",
    "    unique_results = {}\n",
    "    for result_batch in search_results:\n",
    "        # Each result_batch is a QueryResponse with a 'points' attribute\n",
    "        for scored_point in result_batch.points:  # Access the points attribute\n",
    "            if scored_point.id not in unique_results:\n",
    "                unique_results[scored_point.id] = {\n",
    "                    \"score\": scored_point.score,\n",
    "                    \"payload\": scored_point.payload\n",
    "                }\n",
    "    \n",
    "    # Convert to list and sort by score\n",
    "    results = [{\"id\": k, **v} for k, v in unique_results.items()]\n",
    "    results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    return results[:limit]  # Return top N unique results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant_simple(query: str, collection_name: str, limit: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Perform simple search in Qdrant for a single query.\"\"\"\n",
    "    # Generate embedding for the query\n",
    "    embedding = generate_embedding(query)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Perform search\n",
    "    search_results = qdrant_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=embedding,\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "        score_threshold=0.3\n",
    "    )\n",
    "    print(search_results)\n",
    "    search_time = time.time() - start_time\n",
    "    print(f\"Search time: {search_time} seconds\")\n",
    "    # Format results\n",
    "\n",
    "    start_time_1 = time.time()\n",
    "    results = []\n",
    "    for scored_point in search_results.points:\n",
    "        results.append({\n",
    "            \"id\": scored_point.id,\n",
    "            \"score\": scored_point.score,\n",
    "            \"payload\": scored_point.payload\n",
    "        })\n",
    "    format_time = time.time() - start_time_1\n",
    "    print(f\"Format time: {format_time} seconds\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query: str, context: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"Generate a response using OpenAI based on retrieved context.\"\"\"\n",
    "    # Prepare context text from search results\n",
    "    start_time = time.time()\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Document {i+1}:\\nText: {item['payload']['text']}\\nKeywords: {', '.join(item['payload']['keywords'])}\"\n",
    "        for i, item in enumerate(context)\n",
    "    ])\n",
    "    context_time = time.time() - start_time\n",
    "    print(f\"Context time: {context_time} seconds\")\n",
    "    system_prompt = \"\"\"\n",
    "    You are an authoritative academic assistant for Notre Dame University (NDU) providing precise information based on the retrieved documents.\n",
    "    \n",
    "    IMPORTANT GUIDELINES:\n",
    "    1. Provide ONLY ONE definitive answer based on the highest relevance matches in the context.\n",
    "    2. If multiple potential answers exist, choose the one with the strongest evidence in the retrieved documents.\n",
    "    3. Focus exclusively on directly answering the user's question with specific facts from the context.\n",
    "    4. Be extremely precise with numbers, credits, requirements, and program details.\n",
    "    5. If a direct answer isn't clearly available in the context, state this clearly rather than speculating.\n",
    "    6. Format your answer concisely using bold for key facts and figures.\n",
    "    7. Avoid listing multiple possibilities or alternatives unless specifically requested.\n",
    "    \n",
    "    Your goal is to provide the single most accurate answer as if you were an official university representative.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"Question: {query}\\n\\nContext:\\n{context_text}\"\n",
    "    start_time_1 = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"google/gemini-2.0-flash-001\",  # Using a powerful model for response generation\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    response_time = time.time() - start_time_1\n",
    "    print(f\"Response time: {response_time} seconds\")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Search Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query: str):\n",
    "    \"\"\"Complete RAG pipeline from user query to response.\"\"\"\n",
    "    print(f\"Original query: {query}\")\n",
    "    \n",
    "    # # Generate query variations\n",
    "    # variations = generate_query_variations(query)\n",
    "    # all_queries = [query] + variations\n",
    "    \n",
    "    # print(\"Query variations:\")\n",
    "    # for i, q in enumerate(all_queries):\n",
    "    #     print(f\"{i+1}. {q}\")\n",
    "    \n",
    "    # # Remove stop words from all queries\n",
    "    # filtered_queries = [remove_stop_words(q) for q in all_queries]\n",
    "    # print(\"Filtered queries: \",filtered_queries)\n",
    "    \n",
    "    # print(\"After stop word removal:\")\n",
    "    # for i, q in enumerate(filtered_queries):\n",
    "    #     print(f\"{i+1}. {q}\")\n",
    "    \n",
    "    # Search Qdrant\n",
    "    search_results = search_qdrant(query, \"admission_course_guide_json\", limit=5)\n",
    "    \n",
    "    # Generate response\n",
    "    response = generate_response(query, search_results)\n",
    "    \n",
    "    return {\n",
    "        \"original_query\": query,\n",
    "        # \"variations\": variations,\n",
    "        # \"filtered_queries\": filtered_queries,\n",
    "        \"search_results\": search_results,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Search Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline_simple(query: str):\n",
    "    \"\"\"Complete RAG pipeline from user query to response.\"\"\"\n",
    "    print(f\"Original query: {query}\")\n",
    "    \n",
    "    # Search Qdrant with a single query\n",
    "    search_results = search_qdrant_simple(query, \"admission_course_guide_json\", limit=3)\n",
    "    \n",
    "    # Generate response\n",
    "    response = generate_response(query, search_results)\n",
    "    \n",
    "    return {\n",
    "        \"original_query\": query,\n",
    "        \"search_results\": search_results,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: How many credits does a computer science degree have?\n",
      "Embedding time: 1.0684025287628174 seconds\n",
      "points=[ScoredPoint(id=12, version=5, score=0.5776261, payload={'text': 'Bachelor of Science in Computer Science - ABET Accredited Program -\\nBachelor of Science in Computer Science - ABET Accredited Program.', 'keywords': ['BSCS', 'Computer Science', 'ABET', 'curriculum', 'program structure']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=22, version=2, score=0.514978, payload={'text': 'CSC 425 Data Communications and Computer Networks (3 credits)\\nCSC 425 Data Communications and Computer Networks (3 credits)', 'keywords': ['CSC 425', 'Data Communications', 'Computer Networks', '3 credits', 'TCP/IP', 'wireless communication', 'network design', 'prerequisite CSC 345']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=25, version=2, score=0.5139067, payload={'text': 'CSC 463 Advanced Software Development (3 credits)\\nCSC 463 Advanced Software Development (3 credits)', 'keywords': ['CSC 463', 'Advanced Software Development', '3 credits', 'large-scale software', 'maintainable software', 'software engineering', 'prerequisite CSC 305']}, vector=None, shard_key=None, order_value=None)]\n",
      "Search time: 2.2434380054473877 seconds\n",
      "Format time: 0.0 seconds\n",
      "Context time: 0.0 seconds\n",
      "Response time: 1.5880639553070068 seconds\n",
      "Total time taken: 4.901887893676758 seconds\n",
      "\n",
      "Final Response:\n",
      "I am sorry, but the provided documents do not contain the total number of credits required for a computer science degree.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline with a sample query\n",
    "start_time = time.time()\n",
    "result = rag_pipeline_simple(\"How many credits does a computer science degree have?\")\n",
    "end_time = time.time()\n",
    "print(f\"Total time taken: {end_time - start_time} seconds\")\n",
    "# Display the response\n",
    "print(\"\\nFinal Response:\")\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: Does the University have any program for Master's program?\n",
      "Embedding time: 0.4438457489013672 seconds\n",
      "Embedding time: 0.7390108108520508 seconds\n",
      "Embedding time: 1.2095799446105957 seconds\n",
      "Embedding time: 0.4253523349761963 seconds\n",
      "Embedding time: 0.8278212547302246 seconds\n",
      "Embedding time: 0.702434778213501 seconds\n",
      "Embedding time: 0.8332405090332031 seconds\n",
      "Embedding time: 0.7532329559326172 seconds\n",
      "Embedding time: 0.4740478992462158 seconds\n",
      "Embedding time: 0.41017961502075195 seconds\n",
      "Embedding time: 0.585721492767334 seconds\n",
      "Embedding time: 0.5085210800170898 seconds\n",
      "Embedding time: 0.42838287353515625 seconds\n",
      "Embedding time: 0.5225872993469238 seconds\n",
      "Embedding time: 0.6466877460479736 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[173]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test the pipeline with a sample query\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDoes the University have any program for Master\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms program?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Display the response\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFinal Response:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mrag_pipeline\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# # Generate query variations\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# variations = generate_query_variations(query)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# all_queries = [query] + variations\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Search Qdrant\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m search_results = \u001b[43msearch_qdrant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madmission_course_guide\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[32m     25\u001b[39m response = generate_response(query, search_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36msearch_qdrant\u001b[39m\u001b[34m(queries, collection_name, limit)\u001b[39m\n\u001b[32m      4\u001b[39m query_embeddings = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     embedding = \u001b[43mgenerate_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     query_embeddings.append(embedding)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Perform batch search\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_embedding\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate embedding for a text using OpenAI's text-embeddings-small-3 model.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43membeddings_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-embedding-3-small\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m embedding_time = time.time() - start_time\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\openai\\resources\\embeddings.py:128\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    122\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    123\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m             ).tolist()\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\openai\\_base_client.py:969\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    967\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    975\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Test the pipeline with a sample query\n",
    "result = rag_pipeline(\"Does the University have any program for Master's program?\")\n",
    "\n",
    "# Display the response\n",
    "print(\"\\nFinal Response:\")\n",
    "print(result[\"response\"])"
   ]
=======
>>>>>>> Json_POC
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-kuwait-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
