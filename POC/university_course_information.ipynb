{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zohai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from typing import List, Dict, Any\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set up OpenRouter with OpenAI client\n",
    "OPENROUTER_API_KEY = \"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\"\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "embeddings_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Connect to Qdrant (local or cloud)\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://8b6857da-0682-417b-a31b-2a83bef2cab3.us-east-1-0.aws.cloud.qdrant.io\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.dWjs7ZnPcyo0lbk1tvelYBim14HKNwDm1qfWTKaoVoQ\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 41 entries from JSON file\n"
     ]
    }
   ],
   "source": [
    "def read_json_file(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Read JSON file and return its contents.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Read the data\n",
    "file_path = \"../data/processed/admission_guide_PDF_extracted_text.json\"\n",
    "admission_data = read_json_file(file_path)\n",
    "print(f\"Loaded {len(admission_data)} entries from JSON file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Generate embedding for a text using OpenAI's text-embeddings-small-3 model.\"\"\"\n",
    "    start_time = time.time()\n",
    "    response = embeddings_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    embedding_time = time.time() - start_time\n",
    "    print(f\"Embedding time: {embedding_time} seconds\")\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def create_payload(entry: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Create a payload with text, keywords, and metadata for Qdrant.\"\"\"\n",
    "    text = entry.get(\"text\", \"\")\n",
    "    keywords = entry.get(\"keywords\", [])\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"keywords\": keywords,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created collection admission_course_guide\n"
     ]
    }
   ],
   "source": [
    "def create_collection(collection_name: str, vector_size: int = 1536):\n",
    "    \"\"\"Create a collection in Qdrant if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        qdrant_client.get_collection(collection_name)\n",
    "        print(f\"Collection {collection_name} already exists\")\n",
    "    except Exception:\n",
    "        qdrant_client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=models.VectorParams(\n",
    "                size=vector_size,\n",
    "                distance=models.Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "        print(f\"Created collection {collection_name}\")\n",
    "\n",
    "# Create collection for admission data\n",
    "create_collection(\"admission_course_guide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch 1/5\n",
      "Uploaded batch 2/5\n",
      "Uploaded batch 3/5\n",
      "Uploaded batch 4/5\n",
      "Uploaded batch 5/5\n",
      "All data processed and uploaded to Qdrant\n"
     ]
    }
   ],
   "source": [
    "def process_and_upload_data(data: List[Dict[str, Any]], collection_name: str):\n",
    "    \"\"\"Process each entry, generate embedding, and upload to Qdrant.\"\"\"\n",
    "    batch_size = 10  # Process in batches to avoid API rate limits\n",
    "    \n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        \n",
    "        points = []\n",
    "        for j, entry in enumerate(batch):\n",
    "            # Create payload with text and keywords\n",
    "            payload = create_payload(entry)\n",
    "            \n",
    "            # Generate embedding for text content\n",
    "            embedding = generate_embedding(entry[\"text\"])\n",
    "            \n",
    "            # Add to points\n",
    "            points.append(models.PointStruct(\n",
    "                id=i+j,\n",
    "                vector=embedding,\n",
    "                payload=payload\n",
    "            ))\n",
    "        \n",
    "        # Upload batch to Qdrant\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points\n",
    "        )\n",
    "        \n",
    "        print(f\"Uploaded batch {i//batch_size + 1}/{(len(data) + batch_size - 1)//batch_size}\")\n",
    "\n",
    "# Process and upload data\n",
    "process_and_upload_data(admission_data, \"admission_course_guide\")\n",
    "print(\"All data processed and uploaded to Qdrant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching and Testing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(query: str) -> str:\n",
    "    \"\"\"Remove stop words from a query.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = query.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_variations(query: str) -> List[str]:\n",
    "    \"\"\"Generate variations of the query using OpenAI.\"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    Create one alternative versions of the user's query. \n",
    "    Each version should:\n",
    "    1. Maintain the original meaning\n",
    "    2. Use different wording or phrasing\n",
    "    3. Be a complete, well-formed question\n",
    "    \n",
    "    Return ONLY two variations, one per line, with no additional text.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-4.1-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    \n",
    "    variations_text = response.choices[0].message.content\n",
    "    variations = [line.strip() for line in variations_text.split('\\n') if line.strip()]\n",
    "    \n",
    "    # Ensure we have exactly 2 variations\n",
    "    if len(variations) > 1:\n",
    "        variations = variations[:1]\n",
    "    while len(variations) < 1:\n",
    "        variations.append(query)  # Use original query as fallback\n",
    "        \n",
    "    return variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant(queries: List[str], collection_name: str, limit: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Perform batch search in Qdrant for multiple queries.\"\"\"\n",
    "    # Generate embeddings for all queries\n",
    "    query_embeddings = []\n",
    "    for query in queries:\n",
    "        embedding = generate_embedding(query)\n",
    "        query_embeddings.append(embedding)\n",
    "    \n",
    "    # Perform batch search\n",
    "    search_results = qdrant_client.query_batch_points(\n",
    "        collection_name=collection_name,\n",
    "        requests=[\n",
    "            models.QueryRequest(\n",
    "                query=embedding,\n",
    "                limit=limit,\n",
    "                with_payload=True\n",
    "            )\n",
    "            for embedding in query_embeddings\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(search_results)\n",
    "\n",
    "    # Extract unique results\n",
    "    unique_results = {}\n",
    "    for result_batch in search_results:\n",
    "        # Each result_batch is a QueryResponse with a 'points' attribute\n",
    "        for scored_point in result_batch.points:  # Access the points attribute\n",
    "            if scored_point.id not in unique_results:\n",
    "                unique_results[scored_point.id] = {\n",
    "                    \"score\": scored_point.score,\n",
    "                    \"payload\": scored_point.payload\n",
    "                }\n",
    "    \n",
    "    # Convert to list and sort by score\n",
    "    results = [{\"id\": k, **v} for k, v in unique_results.items()]\n",
    "    results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    return results[:limit]  # Return top N unique results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant_simple(query: str, collection_name: str, limit: int = 3) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Perform simple search in Qdrant for a single query.\"\"\"\n",
    "    # Generate embedding for the query\n",
    "    embedding = generate_embedding(query)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Perform search\n",
    "    search_results = qdrant_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=embedding,\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "        score_threshold=0.3\n",
    "    )\n",
    "    print(search_results)\n",
    "    search_time = time.time() - start_time\n",
    "    print(f\"Search time: {search_time} seconds\")\n",
    "    # Format results\n",
    "\n",
    "    start_time_1 = time.time()\n",
    "    results = []\n",
    "    for scored_point in search_results.points:\n",
    "        results.append({\n",
    "            \"id\": scored_point.id,\n",
    "            \"score\": scored_point.score,\n",
    "            \"payload\": scored_point.payload\n",
    "        })\n",
    "    format_time = time.time() - start_time_1\n",
    "    print(f\"Format time: {format_time} seconds\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query: str, context: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"Generate a response using OpenAI based on retrieved context.\"\"\"\n",
    "    # Prepare context text from search results\n",
    "    start_time = time.time()\n",
    "    context_text = \"\\n\\n\".join([\n",
    "        f\"Document {i+1}:\\nText: {item['payload']['text']}\\nKeywords: {', '.join(item['payload']['keywords'])}\"\n",
    "        for i, item in enumerate(context)\n",
    "    ])\n",
    "    context_time = time.time() - start_time\n",
    "    print(f\"Context time: {context_time} seconds\")\n",
    "    system_prompt = \"\"\"\n",
    "    You are an authoritative academic assistant for Notre Dame University (NDU) providing precise information based on the retrieved documents.\n",
    "    \n",
    "    IMPORTANT GUIDELINES:\n",
    "    1. Provide ONLY ONE definitive answer based on the highest relevance matches in the context.\n",
    "    2. If multiple potential answers exist, choose the one with the strongest evidence in the retrieved documents.\n",
    "    3. Focus exclusively on directly answering the user's question with specific facts from the context.\n",
    "    4. Be extremely precise with numbers, credits, requirements, and program details.\n",
    "    5. If a direct answer isn't clearly available in the context, state this clearly rather than speculating.\n",
    "    6. Format your answer concisely using bold for key facts and figures.\n",
    "    7. Avoid listing multiple possibilities or alternatives unless specifically requested.\n",
    "    \n",
    "    Your goal is to provide the single most accurate answer as if you were an official university representative.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"Question: {query}\\n\\nContext:\\n{context_text}\"\n",
    "    start_time_1 = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-4o-mini\",  # Using a powerful model for response generation\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    response_time = time.time() - start_time_1\n",
    "    print(f\"Response time: {response_time} seconds\")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Search Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(query: str):\n",
    "    \"\"\"Complete RAG pipeline from user query to response.\"\"\"\n",
    "    print(f\"Original query: {query}\")\n",
    "    \n",
    "    # # Generate query variations\n",
    "    # variations = generate_query_variations(query)\n",
    "    # all_queries = [query] + variations\n",
    "    \n",
    "    # print(\"Query variations:\")\n",
    "    # for i, q in enumerate(all_queries):\n",
    "    #     print(f\"{i+1}. {q}\")\n",
    "    \n",
    "    # # Remove stop words from all queries\n",
    "    # filtered_queries = [remove_stop_words(q) for q in all_queries]\n",
    "    # print(\"Filtered queries: \",filtered_queries)\n",
    "    \n",
    "    # print(\"After stop word removal:\")\n",
    "    # for i, q in enumerate(filtered_queries):\n",
    "    #     print(f\"{i+1}. {q}\")\n",
    "    \n",
    "    # Search Qdrant\n",
    "    search_results = search_qdrant(query, \"admission_course_guide\", limit=5)\n",
    "    \n",
    "    # Generate response\n",
    "    response = generate_response(query, search_results)\n",
    "    \n",
    "    return {\n",
    "        \"original_query\": query,\n",
    "        # \"variations\": variations,\n",
    "        # \"filtered_queries\": filtered_queries,\n",
    "        \"search_results\": search_results,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Search Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline_simple(query: str):\n",
    "    \"\"\"Complete RAG pipeline from user query to response.\"\"\"\n",
    "    print(f\"Original query: {query}\")\n",
    "    \n",
    "    # Search Qdrant with a single query\n",
    "    search_results = search_qdrant_simple(query, \"admission_course_guide\", limit=3)\n",
    "    \n",
    "    # Generate response\n",
    "    response = generate_response(query, search_results)\n",
    "    \n",
    "    return {\n",
    "        \"original_query\": query,\n",
    "        \"search_results\": search_results,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: What are the available faculties in the University?\n",
      "Embedding time: 0.9884524345397949 seconds\n",
      "points=[ScoredPoint(id=7, version=0, score=0.4404493, payload={'text': 'Degrees Offered - Faculty of Humanities (FH)\\nUndergraduate:\\n- Advertising & Marketing (BA) •○: 102 cr.\\n- Basic Education (BA): 99 cr.\\n- Communication Arts (BA): Journalism & Electronic Media • (102 cr.), Radio/TV •○ (103 cr.)\\n- English Language (BA): 102 cr.\\n- Physical Education & Sport (BA): 99 cr.\\n- Psychology (BA): Clinical, Educational, Industrial (97 cr. each)\\n- Translation & Interpretation (BA): 108 cr.\\nTeaching Diploma (TD): 21 cr. each (Arabic Lang. & Lit., Basic Education, Chemistry, Computer Science, English Lang., Life Science, Mathematics, Physical Education & Sport, Physics)\\nGraduate:\\n- Education (MA): Educational Technology, School Mgt & Edu Leadership, Special Education (33 cr. each)\\n- Educational Psychology (MA): 36 cr.\\n- English Language & Literature (MA): Applied Linguistics & TEFL (30 cr.), Literature (30 cr.)\\n- Media Studies (MA): Advertising, Electronic Journalism, TV Production & Mgt, Media Data Analytics (36 cr. each)\\n- Translation (MA): 36 cr.\\n(Symbols: • North Lebanon Campus, ○ Shouf Campus)', 'keywords': ['NDU FH degrees', 'humanities programs', 'advertising and marketing BA', 'basic education BA', 'communication arts BA', 'journalism degree', 'radio TV degree', 'English language BA', 'physical education BA', 'psychology BA', 'translation BA', 'teaching diploma', 'education MA', 'educational psychology MA', 'English literature MA', 'media studies MA', 'FH courses']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=2, version=0, score=0.42710745, payload={'text': 'Student Life - Student Activities:\\n- Over 30 student clubs and societies.\\n- NDU Model United Nations (MUN) program promotes diversity, respect, and leadership.\\n- Contact (Dept. of Student Activities): T: 09 208 000 Ext. 2348 | E: studentactivities@ndu.edu.lb\\n- Contact (MUN Office): T: 09 208 000 Ext. 2048 | E: mun@ndu.edu.lb\\n\\nSports:\\n- Multipurpose gym for fitness, martial arts, bodybuilding, dancing.\\n- Sports clubs: Basketball, Volleyball, Taekwondo, Aikido, Physical Fitness, Body Building, Tennis, Swimming, Soccer, Rugby, Futsal, Table Tennis, etc.\\n- Contact (Dept. of Athletics): T: 09 208 000 Ext. 2067 | E: athletics@ndu.edu.lb\\n\\nCommunity Services:\\n- Partnerships with NGOs for community projects.\\n- Students plan, adopt, and complete projects with diverse skills.\\n- Contact (Dept. of Community Service and Awareness): T: 09 208 000 Ext. 2068 | E: csa@ndu.edu.lb', 'keywords': ['NDU student life', 'extracurricular activities', 'student clubs', 'student societies', 'Model United Nations', 'MUN', 'university sports', 'gym facilities', 'athletics department', 'community service', 'NGO partnerships', 'student volunteering']}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=11, version=1, score=0.4256167, payload={'text': \"Minors Offered\\nFAAD: Graphic Design (18 cr.), Photography (18 cr.)\\nFBAE: Accounting, Finance, Economics, Management, Marketing Mgt, Distribution & Logistics Mgt, Human Resources Mgt (15 cr. each), Food & Beverage Mgt (19 cr.), Hospitality Mgt (18 cr.), Events Mgt (16 cr.), Entrepreneurship (15 cr.)\\nFE: Engineering Management (18 cr.)\\nFH: English, Advertising & Marketing, Radio & Television, Journalism, Public Relations, Philosophy, Psychology (18 cr. each), French, Physical Edu & Sport, Arabic Lang & Lit, Sociology, Romance Lang (15 cr. each), Translation (16 cr.)\\nFLPS: Political Science, Int'l Affairs & Diplomacy, Public Admin, Middle Eastern Studies, Strategic Studies, Gender Studies, Peace & Conflict Studies, Euro Mediterranean Studies, American Studies (18 cr. each)\\nFNAS: Geographic Info Systems, Mathematics, Physics (15 cr. each), Actuarial Sciences (18 cr.), Biology (17 cr.), Environmental Science (16 cr.)\\nFNHS: Nutrition (15 cr.), Food Safety & Quality Mgt (15 cr.)\", 'keywords': ['NDU minors', 'minor programs', 'FAAD minors', 'FBAE minors', 'FE minors', 'FH minors', 'FLPS minors', 'FNAS minors', 'FNHS minors', 'interdisciplinary studies', 'minor credit hours']}, vector=None, shard_key=None, order_value=None)]\n",
      "Search time: 1.0988554954528809 seconds\n",
      "Format time: 0.0 seconds\n",
      "Context time: 0.0 seconds\n",
      "Response time: 2.892216205596924 seconds\n",
      "Total time taken: 4.9795241355896 seconds\n",
      "\n",
      "Final Response:\n",
      "**The available faculties at Notre Dame University (NDU) include:**\n",
      "\n",
      "1. **Faculty of Humanities (FH)**\n",
      "2. **Faculty of Business Administration and Economics (FBAE)**\n",
      "3. **Faculty of Engineering (FE)**\n",
      "4. **Faculty of Law and Political Science (FLPS)**\n",
      "5. **Faculty of Natural and Applied Sciences (FNAS)**\n",
      "6. **Faculty of Nursing and Health Sciences (FNHS)**\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline with a sample query\n",
    "start_time = time.time()\n",
    "result = rag_pipeline_simple(\"What are the available faculties in the University?\")\n",
    "end_time = time.time()\n",
    "print(f\"Total time taken: {end_time - start_time} seconds\")\n",
    "# Display the response\n",
    "print(\"\\nFinal Response:\")\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: Does the University have any program for Master's program?\n",
      "Embedding time: 0.4438457489013672 seconds\n",
      "Embedding time: 0.7390108108520508 seconds\n",
      "Embedding time: 1.2095799446105957 seconds\n",
      "Embedding time: 0.4253523349761963 seconds\n",
      "Embedding time: 0.8278212547302246 seconds\n",
      "Embedding time: 0.702434778213501 seconds\n",
      "Embedding time: 0.8332405090332031 seconds\n",
      "Embedding time: 0.7532329559326172 seconds\n",
      "Embedding time: 0.4740478992462158 seconds\n",
      "Embedding time: 0.41017961502075195 seconds\n",
      "Embedding time: 0.585721492767334 seconds\n",
      "Embedding time: 0.5085210800170898 seconds\n",
      "Embedding time: 0.42838287353515625 seconds\n",
      "Embedding time: 0.5225872993469238 seconds\n",
      "Embedding time: 0.6466877460479736 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[173]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test the pipeline with a sample query\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDoes the University have any program for Master\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms program?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Display the response\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFinal Response:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mrag_pipeline\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# # Generate query variations\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# variations = generate_query_variations(query)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# all_queries = [query] + variations\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Search Qdrant\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m search_results = \u001b[43msearch_qdrant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madmission_course_guide\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[32m     25\u001b[39m response = generate_response(query, search_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36msearch_qdrant\u001b[39m\u001b[34m(queries, collection_name, limit)\u001b[39m\n\u001b[32m      4\u001b[39m query_embeddings = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     embedding = \u001b[43mgenerate_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     query_embeddings.append(embedding)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Perform batch search\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_embedding\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate embedding for a text using OpenAI's text-embeddings-small-3 model.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43membeddings_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-embedding-3-small\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m embedding_time = time.time() - start_time\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\openai\\resources\\embeddings.py:128\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    122\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    123\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m             ).tolist()\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\openai\\_base_client.py:969\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    967\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    975\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\zohai\\Desktop\\Bilal Bhai Projects\\University Chatbot\\Academics_ChatBot\\venv-kuwait-project\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Test the pipeline with a sample query\n",
    "result = rag_pipeline(\"Does the University have any program for Master's program?\")\n",
    "\n",
    "# Display the response\n",
    "print(\"\\nFinal Response:\")\n",
    "print(result[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-kuwait-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
